{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395db5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from numpy import asarray\n",
    "import math\n",
    "import torch\n",
    "from utils import utils, verification\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73f1624",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check(target_FRS='t1', source_FRS='AWS', dataset='LFW', device='cuda:0', target_bin=False):\n",
    "\n",
    "    # Valid source_FRS (string): t1, t2, t3, t4, t5, AWS, KAIROS, FACEPP\n",
    "    # Valid target_FRS (string): t1, t2, t3, t4, t5\n",
    "    # Valid dataset    (string): LFW, AGE, CFP\n",
    "    \n",
    "    print(\"Source FRS : \"+source_FRS)\n",
    "    print(\"Target FRS : \"+target_FRS)\n",
    "    print(\"Target Dataset : \"+dataset)\n",
    "    \n",
    "    # You can download png files including target images and corresponding reconstructed image using Zenodo link in README file.\n",
    "    # There are small ASR gap in terms of input image files (bin file or png file).\n",
    "    \n",
    "    device = torch.device(device)\n",
    "    blackbox = utils.target_FRS(target_FRS=target_FRS, device=device)\n",
    "    img_size = (112,112)\n",
    "    \n",
    "    if dataset=='LFW':\n",
    "        target_number = 3000\n",
    "        if target_FRS=='t1':\n",
    "            thx=72.54239687627792\n",
    "        elif target_FRS=='t2':\n",
    "            thx=77.29096700560457\n",
    "        elif target_FRS=='t3':\n",
    "            thx=74.33573314862649\n",
    "        elif target_FRS=='t4':\n",
    "            thx=75.81816627143655\n",
    "        elif target_FRS=='t5':\n",
    "            thx=63.57666123410324\n",
    "            img_size = (160,160)\n",
    "            \n",
    "        if target_bin:\n",
    "            print(\"Using bin file instead of png image\")\n",
    "            dataset_dir = \"./utils/dataset/lfw.bin\"\n",
    "            target_dataset = verification.load_bin(dataset_dir, img_size)\n",
    "            target_ind = torch.where(torch.tensor(target_dataset[1]))[0]\n",
    "            \n",
    "    elif dataset==\"AGE\":\n",
    "        target_number = 3000\n",
    "        if target_FRS=='t1':\n",
    "            thx=76.40837722605214\n",
    "        elif target_FRS=='t2':\n",
    "            thx=80.50276553148295\n",
    "        elif target_FRS=='t3':\n",
    "            thx=79.04721580110888\n",
    "        elif target_FRS=='t4':\n",
    "            thx=78.75527640762357\n",
    "        elif target_FRS=='t5':\n",
    "            thx=70.42746205557108\n",
    "            img_size = (160,160)\n",
    "            \n",
    "        if target_bin:\n",
    "            print(\"Using bin file instead of png image\")\n",
    "            dataset_dir = \"./utils/dataset/agedb_30.bin\"\n",
    "            target_dataset = verification.load_bin(dataset_dir, img_size)\n",
    "            target_ind = torch.where(torch.tensor(target_dataset[1]))[0]\n",
    "    \n",
    "    elif dataset==\"CFP\":\n",
    "        target_number = 3500\n",
    "        if target_FRS=='t1':\n",
    "            thx=77.29096700560457\n",
    "        elif target_FRS=='t2':\n",
    "            thx=81.08320374700904\n",
    "        elif target_FRS=='t3':\n",
    "            thx=79.63024019452259\n",
    "        elif target_FRS=='t4':\n",
    "            thx=81.08320374700904\n",
    "        elif target_FRS=='t5':\n",
    "            thx=73.73979529168804\n",
    "            img_size = (160,160)\n",
    "            \n",
    "        if target_bin:\n",
    "            print(\"Using bin file instead of png image\")\n",
    "            dataset_dir = \"./utils/dataset/cfp_fp.bin\"\n",
    "            target_dataset = verification.load_bin(dataset_dir, img_size)\n",
    "            target_ind = torch.where(torch.tensor(target_dataset[1]))[0]\n",
    "    \n",
    "    result = torch.zeros(2,target_number)\n",
    "\n",
    "    for i in tqdm(range(target_number)):\n",
    "        if target_bin:\n",
    "            if target_FRS == 't2':\n",
    "                data_Type1 = (target_dataset[0][0][0::2][int(target_ind[i])]).unsqueeze(0).to(device)\n",
    "                data_Type2 = (target_dataset[0][0][1::2][int(target_ind[i])]).unsqueeze(0).to(device)\n",
    "            else:\n",
    "                data_Type1 = ((target_dataset[0][0][0::2][int(target_ind[i])]-127.5)/255).unsqueeze(0).to(device)\n",
    "                data_Type2 = ((target_dataset[0][0][1::2][int(target_ind[i])]-127.5)/255).unsqueeze(0).to(device)\n",
    "        else:\n",
    "            img_Type1 = Image.open(\"./recon/\"+dataset+\"/Type1_\"+dataset+\"/\"+str(i)+\".png\")\n",
    "            img_Type1 = img_Type1.resize(img_size)\n",
    "            img_Type1 = img_Type1.convert('RGB')\n",
    "            data_Type1 = asarray(img_Type1)\n",
    "            if target_FRS == 't2':\n",
    "                data_Type1 = ((torch.Tensor(data_Type1))).permute(2,0,1).unsqueeze(0).to(device)\n",
    "            else:\n",
    "                data_Type1 = ((torch.tensor(data_Type1)-127.5)/255).permute(2,0,1).unsqueeze(0).to(device)\n",
    "\n",
    "            img_Type2 = Image.open(\"./recon/\"+dataset+\"/Type2_\"+dataset+\"/\"+str(i)+\".png\")\n",
    "            img_Type2 = img_Type2.resize(img_size)\n",
    "            img_Type2 = img_Type2.convert('RGB')\n",
    "            data_Type2 = asarray(img_Type2)\n",
    "            if target_FRS == 't2':\n",
    "                data_Type2 = ((torch.Tensor(data_Type2))).permute(2,0,1).unsqueeze(0).to(device)\n",
    "            else:\n",
    "                data_Type2 = ((torch.tensor(data_Type2)-127.5)/255).permute(2,0,1).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "        img_recon = Image.open(\"./recon/\"+dataset+\"/\"+source_FRS+\"_\"+dataset+\"/\"+str(i)+\".png\")\n",
    "        img_recon = img_recon.resize(img_size)\n",
    "        img_recon = img_recon.convert('RGB')\n",
    "        data_recon = asarray(img_recon)\n",
    "        if target_FRS == 't2':\n",
    "            data_recon = ((torch.Tensor(data_recon))).permute(2,0,1).unsqueeze(0).to(device)\n",
    "        else:\n",
    "            data_recon = ((torch.tensor(data_recon)-127.5)/255).permute(2,0,1).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            feat_Type1 = blackbox(data_Type1)\n",
    "            feat_Type2 = blackbox(data_Type2)\n",
    "            feat_recon = blackbox(data_recon)\n",
    "\n",
    "            feat_Type1 = feat_Type1/feat_Type1.norm()\n",
    "            feat_Type2 = feat_Type2/feat_Type2.norm()\n",
    "            feat_recon = feat_recon/feat_recon.norm()\n",
    "\n",
    "            result[0,i]=(torch.acos((feat_Type1*feat_recon).sum())*180/math.pi).to(\"cpu\")\n",
    "            result[1,i]=(torch.acos((feat_Type2*feat_recon).sum())*180/math.pi).to(\"cpu\")\n",
    "\n",
    "    print(\"Type-1 ASR : \"+str(round(float(100*(result[0,:] <= thx).sum(0)/target_number),2))+\"%\")\n",
    "    print(\"Type-2 ASR : \"+str(round(float(100*(result[1,:] <= thx).sum(0)/target_number),2))+\"%\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4bc1d6-e6a1-4a31-a086-0e3d7f559304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 8 Direct attacks\n",
    "def check_direct(target='t1',target_bin=False):\n",
    "    tab_lfw = check(target,target,'LFW','cuda:0',target_bin)\n",
    "    tab_age = check(target,target,'AGE','cuda:0',target_bin)\n",
    "    tab_cfp = check(target,target,'CFP','cuda:0',target_bin)\n",
    "    return [tab_lfw,tab_age,tab_cfp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d62774-5fdd-422c-b73c-21ab01838894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 8\n",
    "dir_t1 = check_direct('t1')\n",
    "dir_t2 = check_direct('t2')\n",
    "dir_t3 = check_direct('t3')\n",
    "dir_t4 = check_direct('t4')\n",
    "dir_t5 = check_direct('t5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2dab817-63b3-4d85-9603-d7359ba7d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 10 and 11 transfer attacks (against non-commercial targets)\n",
    "# Note that paper only reports for LFW, but we can run for all 3 datasets\n",
    "sources = ['t1','t2','t3','t4','t5','AWS','FACEPP','KAIROS']\n",
    "def check_transfer(target='t1',dataset='LFW',target_bin=False):\n",
    "    return [check(target,source,dataset,'cuda:0',target_bin) for source in sources if source !=target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f81c234-3459-498b-a52e-2531a0df9621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Table 10 (bin)\n",
    "trans_t1 = check_transfer('t1',target_bin=True)\n",
    "trans_t2 = check_transfer('t2',target_bin=True)\n",
    "trans_t3 = check_transfer('t3',target_bin=True)\n",
    "trans_t4 = check_transfer('t4',target_bin=True)\n",
    "trans_t5 = check_transfer('t5',target_bin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4574fb5-e77c-44e9-94b4-f7af9656388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 10 (png)\n",
    "trans_t1_nb = check_transfer('t1',target_bin=False)\n",
    "trans_t2_nb = check_transfer('t2',target_bin=False)\n",
    "trans_t3_nb = check_transfer('t3',target_bin=False)\n",
    "trans_t4_nb = check_transfer('t4',target_bin=False)\n",
    "trans_t5_nb = check_transfer('t5',target_bin=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
